from openai import OpenAI
import requests
import json
import os

# =========================
# CONFIGURACIÃ“N
# =========================

# NOTA: Usa gpt-4o o gpt-3.5-turbo. "gpt-4.1" no existe.
MODELO_OPENAI = "gpt-4o" 

# TU CLAVE DE OPENAI (BÃ³rrala de aquÃ­ si compartes el cÃ³digo)
client = OpenAI(api_key="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")

# TU CLAVE DE FASTAPI (La que definiste en main.py)
API_KEY_FASTAPI = "colchones_secretos_2026_pro_v1" 
API_URL = "http://127.0.0.1:8000/recomendar"

# =========================
# FUNCIÃ“N PARA CONSULTAR LA API
# =========================

def consultar_modelo(datos):
    # 1. AÃ‘ADIMOS LAS CABECERAS DE SEGURIDAD
    headers = {
        "Content-Type": "application/json",
        "x-api-key": API_KEY_FASTAPI # <--- Â¡ESTO FALTABA!
    }
    
    try:
        r = requests.post(API_URL, json=datos, headers=headers, timeout=10)
        r.raise_for_status() # Esto lanzarÃ¡ error si da 403 o 500
        return r.json()
    except requests.exceptions.HTTPError as err:
        return {"error": f"Error conectando con FastAPI: {err}"}
    except Exception as e:
        return {"error": f"Error desconocido: {e}"}

# =========================
# MEMORIA DE CONVERSACIÃ“N
# =========================

messages = [
    {
        "role": "system",
        "content": (
            "Eres un asistente experto en descanso y recomendaciÃ³n de colchones. "
            "Tu objetivo es RECOMENDAR un colchÃ³n, no pedir confirmaciones. "
            "Haz solo las preguntas estrictamente necesarias para obtener estos datos del usuario: "
            "sexo, peso, altura, si duerme en pareja, si tiene dolor de espalda y si tiene molestias antes de dormir. "
            "Cuando tengas TODOS esos datos, DEBES llamar inmediatamente a la funciÃ³n recomendar_colchon. "
            "NO preguntes si quiere mÃ¡s detalles. "
            "NO pidas confirmaciÃ³n. "
            "NO sigas conversando sin llamar a la funciÃ³n. "
            "Tras recibir la respuesta de la funciÃ³n, explica la recomendaciÃ³n de forma clara y directa."
        )
    }
]

# =========================
# DEFINICIÃ“N DE TOOLS
# =========================

tools = [{
    "type": "function",
    "function": {
        "name": "recomendar_colchon",
        "description": "Recomienda el mejor colchÃ³n segÃºn el perfil del usuario",
        "parameters": {
            "type": "object",
            "properties": {
                "sexo": {"type": "string", "enum": ["hombre", "mujer"]},
                "altura": {"type": "number", "description": "en cm"},
                "peso": {"type": "number", "description": "en kg"},
                "duerme_en_pareja": {"type": "boolean"},
                "tiene_dolor_espalda": {"type": "boolean"},
                "molestias_antes": {"type": "boolean"}
            },
            "required": ["sexo", "altura", "peso"]
        }
    }
}]

# =========================
# BUCLE PRINCIPAL
# =========================

print("--- INICIANDO CHAT DE PRUEBA (Escribe 'salir' para terminar) ---")

while True:
    user_input = input("TÃº: ")
    if user_input.lower() in ["salir", "exit"]:
        break

    messages.append({"role": "user", "content": user_input})

    # Llamada a OpenAI
    response = client.chat.completions.create(
        model=MODELO_OPENAI, # Usamos el modelo correcto
        messages=messages,
        tools=tools,
        tool_choice="auto"
    )

    msg = response.choices[0].message

    # =========================
    # LÃ“GICA DE HERRAMIENTAS
    # =========================

    if msg.tool_calls:
        print("ðŸ› ï¸  (El sistema ha detectado todos los datos. Consultando IA Local...)")
        
        args = json.loads(msg.tool_calls[0].function.arguments)

        # âœ… VALORES POR DEFECTO
        args.setdefault("duerme_en_pareja", False)
        args.setdefault("tiene_dolor_espalda", False)
        args.setdefault("molestias_antes", False)

        # LLAMADA A TU API FASTAPI LOCAL
        resultado = consultar_modelo(args)

        # Guardar mensaje del assistant (tool call)
        messages.append(msg)

        # Guardar respuesta de la tool (lo que devolviÃ³ FastAPI)
        messages.append({
            "role": "tool",
            "tool_call_id": msg.tool_calls[0].id,
            "content": json.dumps(resultado)
        })

        # OpenAI genera la respuesta final leyendo el JSON de FastAPI
        final = client.chat.completions.create(
            model=MODELO_OPENAI,
            messages=messages
        )

        print(f"ðŸ¤– Chatbot: {final.choices[0].message.content}")
        
        # Opcional: Romper bucle tras recomendar o seguir charlando
        # break 

    else:
        # Si no tiene datos suficientes, sigue preguntando
        print(f"ðŸ¤– Chatbot: {msg.content}")
        messages.append(msg)